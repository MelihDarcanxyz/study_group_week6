{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoping at this point, we are familiar with classification, object detection can be explained as a classification with localization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "![mater](assets/mcqueen_real.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Localization (and over multiple objects)\n",
    "\n",
    "![mcqueen](assets/mcqueen.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Could be used on any kind of task where finding the location of the object(s) are of any use\n",
    "- Anything related to traffic, pedestrians, types of vehicles, drivable roads, landing zones etc.\n",
    "- Anything related to locating a disease over some type of medical imaging (MRI, Ultrasound, CT ...)\n",
    "- When designing automated stores, factories etc. (Like Amazon Go cashierless stores)\n",
    "\n",
    "this could go on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yea yea yea its all good but how does it come to be and how can I learn / use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we are kind of familiar with a CNN, it acts as a feature extractor, connects to a FCN with number of classes as neurons for output and ta-dah, we have a multi class classifier. \n",
    "\n",
    "![out_neurons](assets/detection_output_neurons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![annotated_out_neurons](assets/annotated_output_neurons.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be penalized with any loss but main logic here is that \n",
    "loss_fn = lambda x, y: (x - y) ** 2\n",
    "prediction = [1] * 8  # P, x, y, w, h, c1, c2, c3\n",
    "label = [1] * 8\n",
    "\n",
    "if prediction[0]:\n",
    "    # calculate loss for only first neuron, we want it to be 0\n",
    "    loss = loss_fn(prediction[0], label[0])\n",
    "else:\n",
    "    # calculate loss over all the other predictions as well\n",
    "    loss = sum([loss_fn(p, l) for p, l in zip(prediction, label)])  # you do not have to use one type of loss function here\n",
    "    # you can use variation of losses which may differ from a bounding box to a class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But how do we classify an unknown number of objects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let me explain while expanding on some utility functions that make object detection the way it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding window detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sliding_snail.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Iterable\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window(image: np.array, step_size: int, window_size: Tuple[int, int]) -> Iterable[int, int, np.ndarray]:\n",
    "    H, W = image.shape  # considering image is 2 channels, you should put a check here\n",
    "    for y in range(0, H, step_size):\n",
    "        for x in range(0, W, step_size):\n",
    "            yield (x, y, image[y: y + window_size[1], x: x + window_size[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intersection Over Union (IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred: Tuple[int, int, int, int], \n",
    "        gt: Tuple[int, int, int, int]) -> float:\n",
    "    \"\"\" in xyxy format, you can write it as xywh format if you'd like \"\"\"\n",
    "    # intersection points\n",
    "    x1 = max(pred[0], gt[0])\n",
    "    y1 = max(pred[0], gt[0])\n",
    "    x2 = max(pred[0], gt[0])\n",
    "    y2 = max(pred[0], gt[0])\n",
    "\n",
    "    # intersection\n",
    "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "\n",
    "    # area of boxes\n",
    "    area_pred = (pred[2] - pred[0] + 1) * (pred[3] - pred[1] + 1)\n",
    "    area_gt = (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1)\n",
    "\n",
    "    iou = intersection / float(area_pred + area_gt - intersection)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Max Suppression (NMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_supression(boxes: list, scores: list, threshold: float = 0.5):\n",
    "    if len(boxes) == 0:\n",
    "        return []  # no prediction to supress\n",
    "    \n",
    "    # it is good to work with np arrays / easier if it is not already that way\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    picked = []\n",
    "    # sorting bbox confidence scores in descending order\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    while len(indices) > 0:\n",
    "        current = indices[0]\n",
    "        picked.append(current)\n",
    "\n",
    "        # compute iou for all of the rest\n",
    "        remaining = indices[1:]\n",
    "        ious = np.array([iou(boxes[current], boxes[i]) for i in remaining])\n",
    "\n",
    "        indices = remaining[ious < threshold]  # elliminate boxes that computes iou less than the threshold\n",
    "\n",
    "    return boxes[picked]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anchor Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchor_boxes(scales: list, aspect_ratios: list, image_size: Tuple[int, int]):\n",
    "    anchor_boxes = []\n",
    "    for scale in scales:\n",
    "        for ratio in aspect_ratios:\n",
    "            width = scale * np.sqrt(ratio)\n",
    "            height = scale / np.sqrt(ratio)\n",
    "            # Create anchor box\n",
    "            anchor_boxes.append([width, height])\n",
    "    return anchor_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deciding bbox locations based on anchor boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: (1 / (1 + np.exp(-x)))\n",
    "\n",
    "def decode_bbox(predicted_bbox, anchor_bbox, grid_cell, stride):\n",
    "    # converting to absolute coordinates w.r.t. anchor box\n",
    "    bx = (sigmoid(predicted_bbox[0]) + grid_cell[0]) * stride\n",
    "    by = (sigmoid(predicted_bbox[1]) + grid_cell[1]) * stride\n",
    "    bw = anchor_bbox[0] * np.exp(predicted_bbox[2])\n",
    "    bh = anchor_bbox[1] * np.exp(predicted_bbox[3])\n",
    "    \n",
    "    return [bx, by, bw, bh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note on how YOLO calculates loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(maybe not the current ones like YOLO7-8-9-10..., can't keep track of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_loss_fn, bce, categorical_ce = None, None, None\n",
    "\n",
    "def yolo_loss(predictions, ground_truth, anchors):\n",
    "    # Split predictions into components\n",
    "    obj_preds = predictions[..., 0]   # objectness\n",
    "    box_preds = predictions[..., 1:5]  # x, y, w, h\n",
    "    class_preds = predictions[..., 6:] # class predictions\n",
    "    \n",
    "    # \"is there\" an object?\n",
    "    obj_loss = bce(obj_preds, ground_truth[..., 0])\n",
    "    \n",
    "    # \"how much\" of the object we have correctly guessed\n",
    "    iou_loss = iou_loss_fn(box_preds, ground_truth[..., 1:5])\n",
    "    \n",
    "    # did we guess \"which\" object it is\n",
    "    class_loss = categorical_ce(class_preds, ground_truth[..., 6:])\n",
    "    \n",
    "    return iou_loss + obj_loss + class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred stuff on yolo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inzva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
